{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.049759469Z",
     "start_time": "2026-02-08T15:13:07.989764603Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "from skimage.measure import shannon_entropy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "from cuml.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "d05f61c7-75e2-48f8-876a-99acfd4d19c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.097468394Z",
     "start_time": "2026-02-08T15:13:08.050680696Z"
    }
   },
   "source": [
    "# Default Configuration\n",
    "CONFIG = {\n",
    "    'sampling': {\n",
    "        'strategy': 'uniform',  # Options: 'uniform', 'dense', 'random'\n",
    "        'n_frames': 16,         # For uniform/random\n",
    "        'frame_skip': 5,        # For dense\n",
    "    },\n",
    "    'resize_dim': (224, 224),\n",
    "    'preprocess': {\n",
    "        'denoise': True,\n",
    "        'normalize_pixel': True, # Pixel value scaling 0-1\n",
    "    },\n",
    "    'normalization': 'minmax', # Options: 'minmax', 'standard'\n",
    "    'n_jobs': -1,\n",
    "\n",
    "    'lbp_radius': 3,\n",
    "    'lbp_points': 8,\n",
    "\n",
    "    'gabor': {\n",
    "        'ksize': 31, # Increased for better texture capture\n",
    "        'sigma': 4.0,\n",
    "        'theta': 0,\n",
    "        'lamda': 10.0,\n",
    "        'gamma': 0.5,\n",
    "        'phi': 0\n",
    "    },\n",
    "\n",
    "    'contour': {\n",
    "        'count' : 3,\n",
    "    },\n",
    "\n",
    "    'lucas_kanade': {\n",
    "        'max_corners': 20,\n",
    "        'quality_level': 0.01,\n",
    "        'min_distance': 10,\n",
    "        'block_size': 7\n",
    "    },\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "79d7e3de-f92f-47b3-8c5d-b3f2df9dd585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.148581986Z",
     "start_time": "2026-02-08T15:13:08.098498225Z"
    }
   },
   "source": [
    "class TemporalFeatureExtractor:\n",
    "    def __init__(self, window_len):\n",
    "        self.window_len = window_len\n",
    "        self.feature_buffer = []\n",
    "\n",
    "    def update(self, frame_features: dict):\n",
    "        self.feature_buffer.append(frame_features)\n",
    "        if len(self.feature_buffer) > self.window_len:\n",
    "            self.feature_buffer.pop(0)\n",
    "        return self._get_temporal_features()\n",
    "\n",
    "    def _get_temporal_features(self):\n",
    "        features = {}\n",
    "        if not self.feature_buffer:\n",
    "            return features\n",
    "\n",
    "        df = pd.DataFrame(self.feature_buffer)\n",
    "\n",
    "        # Only compute temporal stats for numeric columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            features[f\"{col}_temp_mean\"] = df[col].mean()\n",
    "            features[f\"{col}_temp_std\"] = df[col].std(ddof=0)\n",
    "\n",
    "            if len(self.feature_buffer) > 1:\n",
    "                deltas = df[col].diff()\n",
    "                features[f\"{col}_delta_mean\"] = deltas.mean()\n",
    "            else:\n",
    "                features[f\"{col}_delta_mean\"] = 0.0\n",
    "\n",
    "        # Simple motion trend\n",
    "        if len(self.feature_buffer) > 2 and 'motion_avg_intensity' in df.columns:\n",
    "            try:\n",
    "                # Use range as x, intensity as y\n",
    "                slope = np.polyfit(range(len(self.feature_buffer)), df['motion_avg_intensity'], 1)[0]\n",
    "            except:\n",
    "                slope = 0.0\n",
    "        else:\n",
    "            slope = 0.0\n",
    "        features[f\"motion_slope\"] = slope\n",
    "\n",
    "        return features\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.214547175Z",
     "start_time": "2026-02-08T15:13:08.150304203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VideoExtractorFeature:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config if config else CONFIG\n",
    "\n",
    "        if self.config.get('normalization') == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            self.scaler = MinMaxScaler()\n",
    "\n",
    "        # Initialize Gabor Kernel\n",
    "        # Ensure parameters are integers/floats as expected by OpenCV\n",
    "        g_params = self.config['gabor']\n",
    "        self.gabor_kernel = cv.getGaborKernel(\n",
    "            (int(g_params['ksize']), int(g_params['ksize'])),\n",
    "            float(g_params['sigma']),\n",
    "            float(g_params['theta']),\n",
    "            float(g_params['lamda']),\n",
    "            float(g_params['gamma']),\n",
    "            float(g_params['phi']),\n",
    "            ktype=cv.CV_32F\n",
    "        )\n",
    "\n",
    "    def _preprocess_frame(self, frame):\n",
    "        \"\"\"Apply denoising, resizing and normalization.\"\"\"\n",
    "        if frame is None:\n",
    "            return None\n",
    "\n",
    "        # Denoise\n",
    "        if self.config['preprocess'].get('denoise'):\n",
    "            frame = cv.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "        # Resize\n",
    "        frame = cv.resize(frame, self.config['resize_dim'], interpolation=cv.INTER_AREA)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def _get_frame_color_features(self, frame):\n",
    "        hsv_frame = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        features = {}\n",
    "        # RGB Histograms\n",
    "        for i, colour in enumerate(['red', 'blue', 'green']):\n",
    "            channel = rgb_frame[:, :, i]\n",
    "            hist, _ = np.histogram(channel.ravel(), bins=10, range=(0, 256))\n",
    "            hist = hist.astype('float')\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            for j in range(len(hist)):\n",
    "                features[f'color_{colour}_{j}'] = hist[j]\n",
    "\n",
    "        # HSV Stats\n",
    "        for i, column_name in enumerate(['h', 's', 'v']):\n",
    "            channel = hsv_frame[:, :, i]\n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "\n",
    "            features[f'moments_mean_{column_name}'] = mean\n",
    "            features[f'moments_std_{column_name}'] = std\n",
    "\n",
    "            if std > 1e-6:\n",
    "                skew_val = skew(channel.flatten())\n",
    "                features[f'moments_skew_{column_name}'] = 0 if np.isnan(skew_val) else skew_val\n",
    "            else:\n",
    "                features[f'moments_skew_{column_name}'] = 0\n",
    "\n",
    "        avg_rgb  = np.mean(rgb_frame, axis=(0, 1))\n",
    "        features['avg_color_r'] = avg_rgb[0]\n",
    "        features['avg_color_g'] = avg_rgb[1]\n",
    "        features['avg_color_b'] = avg_rgb[2]\n",
    "        return features\n",
    "\n",
    "    def _get_frame_glcm_features(self, grey_frame):\n",
    "        features = {}\n",
    "        # Using fewer distances/angles for efficiency while capturing texture\n",
    "        distances = [1, 3]\n",
    "        angles = [0, np.pi/2] # Horizontal and Vertical\n",
    "\n",
    "        # GLCM requires integer types\n",
    "        grey_frame_int = (grey_frame).astype(np.uint8)\n",
    "\n",
    "        glcm = graycomatrix(grey_frame_int, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "        props = ['contrast', 'dissimilarity', 'homogeneity', 'correlation', 'energy']\n",
    "        for prop in props:\n",
    "            val = graycoprops(glcm, prop).ravel()\n",
    "            # Average over all distances/angles to reduce feature dimensionality\n",
    "            features[f'glcm_{prop}_mean'] = np.mean(val)\n",
    "            features[f'glcm_{prop}_std'] = np.std(val)\n",
    "\n",
    "        features['glcm_entropy'] = shannon_entropy(grey_frame)\n",
    "        return features\n",
    "\n",
    "    def _lbp_features(self, grey_frame):\n",
    "        # LBP usually on integer images? scikit-image handles float but warns.\n",
    "        # Ensure it works.\n",
    "        lbp = local_binary_pattern(grey_frame, self.config['lbp_points'], self.config['lbp_radius'], method='uniform')\n",
    "        # Uniform LBP histogram\n",
    "        n_bins = self.config['lbp_points'] + 2\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        hist = hist.astype('float')\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "\n",
    "        features = {}\n",
    "        for i in range(len(hist)):\n",
    "            features[f'lbp_{i}'] = hist[i]\n",
    "        return features\n",
    "\n",
    "    def _get_gabor_features(self, grey_frame):\n",
    "        gabor_features = cv.filter2D(grey_frame, cv.CV_32F, self.gabor_kernel)\n",
    "\n",
    "        mean = np.mean(gabor_features)\n",
    "        std = np.std(gabor_features)\n",
    "        features = {\n",
    "            'gabor_mean': mean,\n",
    "            'gabor_std': std\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def _get_canny_features(self, grey_frame):\n",
    "        sigma = 0.33\n",
    "        v = np.median(grey_frame)\n",
    "        lower = int(max(0, (1.0 - sigma) * v))\n",
    "        upper = int(min(255, (1.0 + sigma) * v))\n",
    "        edges = cv.Canny(grey_frame, lower, upper)\n",
    "\n",
    "        # Edge density\n",
    "        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
    "        features = {'canny_edge_density': edge_density}\n",
    "        return features\n",
    "\n",
    "    def _get_contour_features(self, grey_frame):\n",
    "        # Binary threshold\n",
    "        _, img_th = cv.threshold(grey_frame, 127, 255, cv.THRESH_BINARY)\n",
    "        contours, _ = cv.findContours(img_th, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        features = {}\n",
    "        count = self.config['contour']['count']\n",
    "\n",
    "        # Sort by area\n",
    "        sorted_contours = sorted(contours, key=cv.contourArea, reverse=True)\n",
    "\n",
    "        for i in range(count):\n",
    "            if i < len(sorted_contours):\n",
    "                c = sorted_contours[i]\n",
    "                area = cv.contourArea(c)\n",
    "                perimeter = cv.arcLength(c, True)\n",
    "                if perimeter == 0: perimeter = 1e-7\n",
    "                circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "\n",
    "                features[f'contour_{i}_area'] = area\n",
    "                features[f'contour_{i}_circularity'] = circularity\n",
    "            else:\n",
    "                features[f'contour_{i}_area'] = 0\n",
    "                features[f'contour_{i}_circularity'] = 0\n",
    "        return features\n",
    "\n",
    "    def _get_hog_features(self, grey_frame):\n",
    "        # Using smaller image for HOG to reduce dimensions\n",
    "        features = {}\n",
    "        small = cv.resize(grey_frame, (64, 64))\n",
    "        hog_feats = hog(small, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
    "\n",
    "        # Statistical summary of HOG\n",
    "        features['hog_mean'] = np.mean(hog_feats)\n",
    "        features['hog_std'] = np.std(hog_feats)\n",
    "        features['hog_max'] = np.max(hog_feats)\n",
    "        return features\n",
    "\n",
    "    def _get_optical_flow_features(self, prev_grey, curr_grey):\n",
    "        features = {}\n",
    "\n",
    "        # Farneback Dense Optical Flow\n",
    "        flow = cv.calcOpticalFlowFarneback(prev_grey, curr_grey, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "        features['flow_mag_mean'] = np.mean(mag)\n",
    "        features['flow_mag_std'] = np.std(mag)\n",
    "        features['flow_ang_mean'] = np.mean(ang)\n",
    "\n",
    "        # Histogram of flow magnitude\n",
    "        hist_mag, _ = np.histogram(mag, bins=5, range=(0, 10))\n",
    "        hist_mag = hist_mag.astype(float) / (hist_mag.sum() + 1e-7)\n",
    "        for i, val in enumerate(hist_mag):\n",
    "            features[f'flow_mag_hist_{i}'] = val\n",
    "\n",
    "        return features\n",
    "\n",
    "    def _process_video(self, row: dict):\n",
    "        video_id = row['index']\n",
    "        video_path = row.get('clip_path', '')\n",
    "        if not video_path:\n",
    "            return []\n",
    "\n",
    "        cap = cv.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if not frames:\n",
    "            return []\n",
    "\n",
    "        total_frames = len(frames)\n",
    "        selected_indices = []\n",
    "        strategy = self.config['sampling']['strategy']\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            n_frames = self.config['sampling']['n_frames']\n",
    "            if total_frames <= n_frames:\n",
    "                selected_indices = list(range(total_frames))\n",
    "            else:\n",
    "                selected_indices = np.linspace(0, total_frames - 1, n_frames).astype(int)\n",
    "        elif strategy == 'random':\n",
    "            n_frames = self.config['sampling']['n_frames']\n",
    "            if total_frames <= n_frames:\n",
    "                selected_indices = list(range(total_frames))\n",
    "            else:\n",
    "                indices = np.random.choice(total_frames, n_frames, replace=False)\n",
    "                selected_indices = np.sort(indices)\n",
    "        else: # dense\n",
    "            skip = self.config['sampling']['frame_skip']\n",
    "            selected_indices = range(0, total_frames, skip)\n",
    "\n",
    "        video_features = []\n",
    "        prev_grey_frame = None\n",
    "        # Should create new instance per video to avoid state bleed\n",
    "        temporal_extractor = TemporalFeatureExtractor(5)\n",
    "\n",
    "        for idx in selected_indices:\n",
    "            frame = frames[idx]\n",
    "            frame = self._preprocess_frame(frame)\n",
    "            grey_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            frame_feat = {'index': video_id}\n",
    "\n",
    "            # Spatial Features\n",
    "            frame_feat.update(self._get_frame_color_features(frame))\n",
    "            frame_feat.update(self._get_frame_glcm_features(grey_frame))\n",
    "            frame_feat.update(self._lbp_features(grey_frame))\n",
    "            frame_feat.update(self._get_gabor_features(grey_frame))\n",
    "            frame_feat.update(self._get_canny_features(grey_frame))\n",
    "            frame_feat.update(self._get_contour_features(grey_frame))\n",
    "            frame_feat.update(self._get_hog_features(grey_frame))\n",
    "\n",
    "            # Temporal/Motion Features\n",
    "            if prev_grey_frame is not None:\n",
    "                motion_feat = self._get_optical_flow_features(prev_grey_frame, grey_frame)\n",
    "                temporal_stats = temporal_extractor.update(motion_feat)\n",
    "                frame_feat.update(motion_feat)\n",
    "                frame_feat.update(temporal_stats)\n",
    "            else:\n",
    "                # First frame, zero motion\n",
    "                motion_feat = self._get_optical_flow_features(grey_frame, grey_frame) # Zero flow basically\n",
    "                # Since _get_optical_flow calculates flow between two frames, for first frame we can pass SAME frame -> 0 flow\n",
    "                temporal_stats = temporal_extractor.update(motion_feat)\n",
    "                frame_feat.update(motion_feat)\n",
    "                frame_feat.update(temporal_stats)\n",
    "\n",
    "            video_features.append(frame_feat)\n",
    "            prev_grey_frame = grey_frame\n",
    "\n",
    "        return video_features\n",
    "\n",
    "    def process_dataset(self, df: pd.DataFrame, is_test=False):\n",
    "        print(f\"Processing {len(df)} videos with {self.config['n_jobs']} jobs...\")\n",
    "        rows = df.reset_index().to_dict('records')\n",
    "\n",
    "        # Using joblib backend 'threading' might be safer for OpenCV which releases GIL?\n",
    "        # But 'loky' (default) is safer for process isolation.\n",
    "        nested_results = Parallel(n_jobs=self.config['n_jobs'])(delayed(self._process_video)(row) for row in rows)\n",
    "\n",
    "        flatten_results = [item for sub_list in nested_results if sub_list for item in sub_list]\n",
    "        feature_df = pd.DataFrame(flatten_results)\n",
    "\n",
    "        feature_names = [col for col in feature_df.columns if col not in ['index', 'encoded_label']]\n",
    "        # Fill NaNs\n",
    "        feature_df[feature_names] = feature_df[feature_names].fillna(0)\n",
    "        feature_df[feature_names] = feature_df[feature_names].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "        return feature_df\n",
    "\n",
    "    def aggregate_features(self, feature_df: pd.DataFrame):\n",
    "        \"\"\"Aggregate frame-level features to video-level features.\"\"\"\n",
    "        if feature_df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Group by video index\n",
    "        # We compute mean, std, min, max for each numerical feature\n",
    "        agg_funcs = ['mean', 'std', 'min', 'max']\n",
    "\n",
    "        # Drop non-numeric for aggregation\n",
    "        numeric_cols = feature_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if 'index' in numeric_cols: numeric_cols.remove('index')\n",
    "        if 'encoded_label' in numeric_cols: numeric_cols.remove('encoded_label')\n",
    "\n",
    "        agg_dict = {col: agg_funcs for col in numeric_cols}\n",
    "\n",
    "        # We need 'index' to group\n",
    "        grouped = feature_df.groupby('index')\n",
    "\n",
    "        agg_df = grouped[numeric_cols].agg(agg_funcs)\n",
    "\n",
    "        # Flatten MultiIndex columns\n",
    "        agg_df.columns = ['_'.join(col).strip() for col in agg_df.columns.values]\n",
    "\n",
    "        return agg_df\n",
    "\n",
    "    def fit_transform_scaler(self, df, is_test=False):\n",
    "        # Helper to scale features\n",
    "        feature_names = [col for col in df.columns if col not in ['index', 'encoded_label']]\n",
    "\n",
    "        # Check if scalar is initialized (it is in init)\n",
    "\n",
    "        if is_test:\n",
    "            # Handle unseen columns in test?\n",
    "            # Ensure columns match scaler?\n",
    "            # For now assume consistent feature extraction\n",
    "            df[feature_names] = self.scaler.transform(df[feature_names])\n",
    "        else:\n",
    "            df[feature_names] = self.scaler.fit_transform(df[feature_names])\n",
    "        return df\n"
   ],
   "id": "15eb3a1e01f06843",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b5888fea-ba0f-4cac-8fc0-c9a5d377ae93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.262357933Z",
     "start_time": "2026-02-08T15:13:08.215547830Z"
    }
   },
   "source": [
    "# Setup Directories\n",
    "OUTPUT_DIR = \"results_classical\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    train = pd.read_csv(\"./dataset/splits/train.csv\", index_col='index')\n",
    "    val = pd.read_csv(\"./dataset/splits/validation.csv\", index_col='index')\n",
    "    test = pd.read_csv(\"./dataset/splits/test.csv\", index_col='index')\n",
    "    return train, val, test\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.310268821Z",
     "start_time": "2026-02-08T15:13:08.263200965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_svm_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 1e-2, 1e2, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-3, 1e1, log=True),\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "        }\n",
    "\n",
    "        clf = SVC(**params, probability=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing SVM...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (SVM):\", study.best_params)\n",
    "    return study.best_params\n"
   ],
   "id": "cb87ad028433d315",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.358425120Z",
     "start_time": "2026-02-08T15:13:08.311199199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_rf_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        }\n",
    "\n",
    "        clf = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing Random Forest...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (RF):\", study.best_params)\n",
    "    return study.best_params\n"
   ],
   "id": "22a27e2a4a9b7df3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "77e49e17-d9b6-4009-8534-aa0cac8f7497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.405201236Z",
     "start_time": "2026-02-08T15:13:08.359327820Z"
    }
   },
   "source": [
    "def train_knn_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 3, 20),\n",
    "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            'metric': trial.suggest_categorical('metric', ['euclidean', 'manhattan']),\n",
    "        }\n",
    "\n",
    "        clf = KNeighborsClassifier(**params, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing KNN...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (KNN):\", study.best_params)\n",
    "    return study.best_params\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "19c34ea9-8504-4fbb-978a-00cef273a826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.451447303Z",
     "start_time": "2026-02-08T15:13:08.406021583Z"
    }
   },
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n",
    "    plt.close()\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "66b6fe161c331f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.499361047Z",
     "start_time": "2026-02-08T15:13:08.452428736Z"
    }
   },
   "source": [
    "def plot_roc_curve(clf, X_test, y_test, label_encoder, filename):\n",
    "    # Only works if probability=True or decision_function available\n",
    "    # cuML SVC might not support predict_proba easily for all kernels?\n",
    "    # sklearn SVC needs probability=True.\n",
    "\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test)\n",
    "    except:\n",
    "        try:\n",
    "             y_score = clf.decision_function(X_test)\n",
    "        except:\n",
    "            print(\"Model does not support probability/decision function. Skipping ROC.\")\n",
    "            return\n",
    "\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "\n",
    "    # Binarize output\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "    plt.figure()\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=colors[i], lw=2, label=f'Class {label_encoder.classes_[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n",
    "    plt.close()\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "46eca334-6976-45ea-87c3-6c80bf87124f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:13:08.552142930Z",
     "start_time": "2026-02-08T15:13:08.500080751Z"
    }
   },
   "source": [
    "def run_experiment(name, config_update):\n",
    "    print(f\"\\n--- Running Experiment: {name} ---\")\n",
    "\n",
    "    # Reload Config\n",
    "    cfg = CONFIG.copy()\n",
    "    cfg.update(config_update)\n",
    "\n",
    "    extractor = VideoExtractorFeature(cfg)\n",
    "\n",
    "    train_df, val_df, test_df = load_data()\n",
    "\n",
    "    # Process\n",
    "    t0 = time.time()\n",
    "    print(\"Extracting features...\")\n",
    "    X_train_frames = extractor.process_dataset(train_df)\n",
    "    X_val_frames = extractor.process_dataset(val_df)\n",
    "\n",
    "    # Scaling\n",
    "    X_train_frames = extractor.fit_transform_scaler(X_train_frames)\n",
    "    X_val_frames = extractor.fit_transform_scaler(X_val_frames, is_test=True)\n",
    "\n",
    "    print(f\"Extraction time: {time.time()-t0:.2f}s\")\n",
    "\n",
    "    # Merge Labels\n",
    "    # We need to map back to labels.\n",
    "    # process_dataset returns df with 'index'\n",
    "    # train_df index is 'index'\n",
    "\n",
    "    train_merged = pd.merge(train_df.reset_index(), X_train_frames, on='index')\n",
    "    val_merged = pd.merge(val_df.reset_index(), X_val_frames, on='index')\n",
    "\n",
    "    # Encode Labels\n",
    "    le = LabelEncoder()\n",
    "    # Fit on all possible labels to avoid unseen label errors\n",
    "    all_labels = pd.concat([train_merged['label'], val_merged['label']]).unique()\n",
    "    le.fit(all_labels)\n",
    "\n",
    "    y_train_enc = le.transform(train_merged['label'])\n",
    "    y_val_enc = le.transform(val_merged['label'])\n",
    "\n",
    "    # Mode 1: Frame Level Classification + Voting\n",
    "    print(\"Training Frame-Level Model...\")\n",
    "    feature_cols = [c for c in X_train_frames.columns if c not in ['index', 'encoded_label']]\n",
    "\n",
    "    X_train_f = train_merged[feature_cols].values\n",
    "    X_val_f = val_merged[feature_cols].values\n",
    "\n",
    "    best_params = train_svm_optuna(X_train_f, y_train_enc, X_val_f, y_val_enc, trials=10)\n",
    "\n",
    "    best_clf = SVC(**best_params, probability=True)\n",
    "    best_clf.fit(X_train_f, y_train_enc)\n",
    "\n",
    "    # Evaluate Video Level (Voting)\n",
    "    val_preds_frames = best_clf.predict(X_val_f)\n",
    "    val_merged['pred'] = val_preds_frames\n",
    "\n",
    "    y_true_vid = []\n",
    "    y_pred_vid = []\n",
    "\n",
    "    for vid, group in val_merged.groupby('index'):\n",
    "        y_true_vid.append(le.transform([group['label'].iloc[0]])[0])\n",
    "        # Mode of frame predictions\n",
    "        mode_pred = group['pred'].mode().iloc[0]\n",
    "        y_pred_vid.append(mode_pred)\n",
    "\n",
    "    acc = accuracy_score(y_true_vid, y_pred_vid)\n",
    "    print(f\"Video Level Accuracy (Voting): {acc:.4f}\")\n",
    "\n",
    "    plot_confusion_matrix(y_true_vid, y_pred_vid, le.classes_, f\"Confusion Matrix - {name} (Voting)\", f\"cm_{name}_voting.png\")\n",
    "\n",
    "    # Mode 2: Video Level Aggregation\n",
    "    print(\"Training Video-Level Aggregated Model...\")\n",
    "\n",
    "    # Aggregate\n",
    "    # Note: re-process from raw X_train_frames (already scaled)\n",
    "    # Aggregating SCALED features is fine.\n",
    "\n",
    "    X_train_vid_df = extractor.aggregate_features(X_train_frames)\n",
    "    X_val_vid_df = extractor.aggregate_features(X_val_frames)\n",
    "\n",
    "    # We lost labels in aggregation, need to re-merge\n",
    "    # X_train_vid_df index is 'index' (video id)\n",
    "\n",
    "    train_vid_merged = pd.merge(train_df, X_train_vid_df, left_index=True, right_index=True)\n",
    "    val_vid_merged = pd.merge(val_df, X_val_vid_df, left_index=True, right_index=True)\n",
    "\n",
    "    feat_cols_vid = [c for c in train_vid_merged.columns if c not in train_df.columns]\n",
    "\n",
    "    X_train_v = train_vid_merged[feat_cols_vid].values\n",
    "    y_train_v = le.transform(train_vid_merged['label'])\n",
    "\n",
    "    X_val_v = val_vid_merged[feat_cols_vid].values\n",
    "    y_val_v = le.transform(val_vid_merged['label'])\n",
    "\n",
    "    # PCA (Optional - req 4.4)\n",
    "    pca = PCA(n_components=0.95) # Keep 95% variance\n",
    "    X_train_v_pca = pca.fit_transform(X_train_v)\n",
    "    X_val_v_pca = pca.transform(X_val_v)\n",
    "    print(f\"PCA reduced dim from {X_train_v.shape[1]} to {X_train_v_pca.shape[1]}\")\n",
    "\n",
    "    # 1. SVM Video\n",
    "    best_params_vid_svm = train_svm_optuna(X_train_v_pca, y_train_v, X_val_v_pca, y_val_v, trials=10)\n",
    "    best_clf_vid_svm = SVC(**best_params_vid_svm, probability=True)\n",
    "    best_clf_vid_svm.fit(X_train_v_pca, y_train_v)\n",
    "    vid_preds_svm = best_clf_vid_svm.predict(X_val_v_pca)\n",
    "    acc_vid_svm = accuracy_score(y_val_v, vid_preds_svm)\n",
    "    print(f\"Video Level Accuracy (SVM + PCA): {acc_vid_svm:.4f}\")\n",
    "    plot_confusion_matrix(y_val_v, vid_preds_svm, le.classes_, f\"Confusion Matrix - {name} (SVM)\", f\"cm_{name}_svm.png\")\n",
    "    plot_roc_curve(best_clf_vid_svm, X_val_v_pca, y_val_v, le, f\"roc_{name}_svm.png\")\n",
    "\n",
    "    # 2. Random Forest Video\n",
    "    best_params_vid_rf = train_rf_optuna(X_train_v, y_train_v, X_val_v, y_val_v, trials=10)\n",
    "    best_clf_vid_rf = RandomForestClassifier(**best_params_vid_rf, random_state=42)\n",
    "    best_clf_vid_rf.fit(X_train_v, y_train_v)\n",
    "    vid_preds_rf = best_clf_vid_rf.predict(X_val_v)\n",
    "    acc_vid_rf = accuracy_score(y_val_v, vid_preds_rf)\n",
    "    print(f\"Video Level Accuracy (RF): {acc_vid_rf:.4f}\")\n",
    "    plot_confusion_matrix(y_val_v, vid_preds_rf, le.classes_, f\"Confusion Matrix - {name} (RF)\", f\"cm_{name}_rf.png\")\n",
    "    plot_roc_curve(best_clf_vid_rf, X_val_v, y_val_v, le, f\"roc_{name}_rf.png\")\n",
    "\n",
    "    # 3. KNN Video\n",
    "    best_params_vid_knn = train_knn_optuna(X_train_v_pca, y_train_v, X_val_v_pca, y_val_v, trials=10)\n",
    "    best_clf_vid_knn = KNeighborsClassifier(**best_params_vid_knn)\n",
    "    best_clf_vid_knn.fit(X_train_v_pca, y_train_v)\n",
    "    vid_preds_knn = best_clf_vid_knn.predict(X_val_v_pca)\n",
    "    acc_vid_knn = accuracy_score(y_val_v, vid_preds_knn)\n",
    "    print(f\"Video Level Accuracy (KNN + PCA): {acc_vid_knn:.4f}\")\n",
    "    plot_confusion_matrix(y_val_v, vid_preds_knn, le.classes_, f\"Confusion Matrix - {name} (KNN)\", f\"cm_{name}_knn.png\")\n",
    "    plot_roc_curve(best_clf_vid_knn, X_val_v_pca, y_val_v, le, f\"roc_{name}_knn.png\")\n",
    "\n",
    "    return {\n",
    "        'frame_voting_acc': acc,\n",
    "        'video_agg_acc_svm': acc_vid_svm,\n",
    "        'video_agg_acc_rf': acc_vid_rf,\n",
    "        'video_agg_acc_knn': acc_vid_knn,\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "b2a271760d082fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:16:37.980556732Z",
     "start_time": "2026-02-08T15:13:08.552936621Z"
    }
   },
   "source": [
    "    try:\n",
    "        print(\"Starting main...\")\n",
    "        # 1. Baseline: Uniform Sampling, MinMax\n",
    "        res_baseline = run_experiment('baseline_uniform_minmax', {\n",
    "            'sampling': {'strategy': 'uniform', 'n_frames': 16},\n",
    "            'normalization': 'minmax'\n",
    "        })\n",
    "\n",
    "        # 2. Improved: Uniform, StandardScaler (Req 3)\n",
    "        res_std = run_experiment('uniform_stdscaler', {\n",
    "            'sampling': {'strategy': 'uniform', 'n_frames': 16},\n",
    "            'normalization': 'standard'\n",
    "        })\n",
    "\n",
    "        # 3. Improved: Dense Sampling (Req 1), standard scaler\n",
    "        res_dense = run_experiment('dense_stdscaler', {\n",
    "            'sampling': {'strategy': 'dense', 'frame_skip': 5},\n",
    "            'normalization': 'standard'\n",
    "        })\n",
    "\n",
    "        print(\"\\n--- Summary ---\")\n",
    "        print(\"Baseline (Voting):\", res_baseline['frame_voting_acc'])\n",
    "        print(\"Baseline (SVM Agg):\", res_baseline['video_agg_acc_svm'])\n",
    "        print(\"Baseline (RF Agg):\", res_baseline['video_agg_acc_rf'])\n",
    "        print(\"Baseline (KNN Agg):\", res_baseline['video_agg_acc_knn'])\n",
    "\n",
    "        print(\"\\nStdScaler (Voting):\", res_std['frame_voting_acc'])\n",
    "        print(\"StdScaler (SVM Agg):\", res_std['video_agg_acc_svm'])\n",
    "        print(\"StdScaler (RF Agg):\", res_std['video_agg_acc_rf'])\n",
    "        print(\"StdScaler (KNN Agg):\", res_std['video_agg_acc_knn'])\n",
    "\n",
    "        print(\"\\nDense (Voting):\", res_dense['frame_voting_acc'])\n",
    "        print(\"Dense (SVM Agg):\", res_dense['video_agg_acc_svm'])\n",
    "        print(\"Dense (RF Agg):\", res_dense['video_agg_acc_rf'])\n",
    "        print(\"Dense (KNN Agg):\", res_dense['video_agg_acc_knn'])\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"CRITICAL ERROR: {e}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main...\n",
      "\n",
      "--- Running Experiment: baseline_uniform_minmax ---\n",
      "Extracting features...\n",
      "Processing 240 videos with -1 jobs...\n",
      "Processing 30 videos with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:37,706]\u001B[0m A new study created in memory with name: no-name-7fa2b97c-842e-4b34-8a8b-bd72dce84afb\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction time: 29.14s\n",
      "Training Frame-Level Model...\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:38,891]\u001B[0m Trial 0 finished with value: 0.98125 and parameters: {'C': 44.029503622045624, 'gamma': 0.7706949835469655, 'kernel': 'linear'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:39,609]\u001B[0m Trial 1 finished with value: 0.8458333333333333 and parameters: {'C': 1.8244183815173216, 'gamma': 0.0010256799247576804, 'kernel': 'poly'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:40,331]\u001B[0m Trial 2 finished with value: 0.8458333333333333 and parameters: {'C': 7.559321515388865, 'gamma': 0.001143871696222311, 'kernel': 'poly'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:40,983]\u001B[0m Trial 3 finished with value: 0.9770833333333333 and parameters: {'C': 2.9289251423493536, 'gamma': 2.36813083743141, 'kernel': 'poly'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:41,672]\u001B[0m Trial 4 finished with value: 0.6416666666666667 and parameters: {'C': 0.0231998194362148, 'gamma': 4.32329722213996, 'kernel': 'rbf'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:42,220]\u001B[0m Trial 5 finished with value: 0.89375 and parameters: {'C': 2.074882825451861, 'gamma': 0.0031901141474600806, 'kernel': 'rbf'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:43,642]\u001B[0m Trial 6 finished with value: 0.7604166666666666 and parameters: {'C': 52.626954936824134, 'gamma': 8.534460873668717, 'kernel': 'rbf'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:44,283]\u001B[0m Trial 7 finished with value: 0.9770833333333333 and parameters: {'C': 0.17180920354492044, 'gamma': 0.5500380749992885, 'kernel': 'poly'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:44,948]\u001B[0m Trial 8 finished with value: 0.9770833333333333 and parameters: {'C': 8.701096103975512, 'gamma': 2.824458721683726, 'kernel': 'poly'}. Best is trial 0 with value: 0.98125.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:45,471]\u001B[0m Trial 9 finished with value: 0.9916666666666667 and parameters: {'C': 5.505601269665177, 'gamma': 0.08123494588590749, 'kernel': 'rbf'}. Best is trial 9 with value: 0.9916666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 5.505601269665177, 'gamma': 0.08123494588590749, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:46,185]\u001B[0m A new study created in memory with name: no-name-4991524f-e9e6-4d3e-9849-ded09a71e344\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Level Accuracy (Voting): 1.0000\n",
      "Training Video-Level Aggregated Model...\n",
      "PCA reduced dim from 432 to 35\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:46,377]\u001B[0m Trial 0 finished with value: 1.0 and parameters: {'C': 6.974262538406011, 'gamma': 0.07412541031124908, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:46,517]\u001B[0m Trial 1 finished with value: 0.7666666666666667 and parameters: {'C': 0.02607327420032932, 'gamma': 0.022360605962535272, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:46,673]\u001B[0m Trial 2 finished with value: 0.9666666666666667 and parameters: {'C': 42.390353146900054, 'gamma': 0.18994826444447813, 'kernel': 'poly'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:46,808]\u001B[0m Trial 3 finished with value: 0.43333333333333335 and parameters: {'C': 0.04214716899433626, 'gamma': 0.0141841325171663, 'kernel': 'poly'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:46,996]\u001B[0m Trial 4 finished with value: 1.0 and parameters: {'C': 3.9072090703104605, 'gamma': 0.6107776959075499, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:47,163]\u001B[0m Trial 5 finished with value: 1.0 and parameters: {'C': 10.766491790408299, 'gamma': 0.07693891871429885, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:47,336]\u001B[0m Trial 6 finished with value: 0.8 and parameters: {'C': 0.01316333791629138, 'gamma': 0.01144525989446844, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:47,527]\u001B[0m Trial 7 finished with value: 1.0 and parameters: {'C': 98.42130598748201, 'gamma': 8.369150243785173, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:47,738]\u001B[0m Trial 8 finished with value: 1.0 and parameters: {'C': 38.95281301106479, 'gamma': 0.024779182809934828, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:47,928]\u001B[0m Trial 9 finished with value: 1.0 and parameters: {'C': 51.24482993756714, 'gamma': 0.80283240605027, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 6.974262538406011, 'gamma': 0.07412541031124908, 'kernel': 'rbf'}\n",
      "Video Level Accuracy (SVM + PCA): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:48,268]\u001B[0m A new study created in memory with name: no-name-a0ce79f4-d6ca-4b76-8a75-dae844da0f1e\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:48,569]\u001B[0m Trial 0 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 80, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.9333333333333333.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:48,966]\u001B[0m Trial 1 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 120, 'max_depth': 46, 'min_samples_split': 12, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:49,823]\u001B[0m Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 231, 'max_depth': 25, 'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:50,121]\u001B[0m Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 95, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:50,828]\u001B[0m Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 199, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:51,964]\u001B[0m Trial 5 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 283, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:52,722]\u001B[0m Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 290, 'max_depth': 34, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:53,501]\u001B[0m Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 285, 'max_depth': 46, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:54,376]\u001B[0m Trial 8 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 219, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 3 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:54,841]\u001B[0m Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 236, 'max_depth': 27, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 3 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (RF): {'n_estimators': 95, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}\n",
      "Video Level Accuracy (RF): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:43:55,120]\u001B[0m A new study created in memory with name: no-name-6bd62aaf-227e-4c80-9d4a-638ee898b9e0\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,155]\u001B[0m Trial 0 finished with value: 0.8 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,158]\u001B[0m Trial 1 finished with value: 0.8 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,161]\u001B[0m Trial 2 finished with value: 0.6666666666666666 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,163]\u001B[0m Trial 3 finished with value: 0.9 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 3 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,165]\u001B[0m Trial 4 finished with value: 0.7 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 3 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,167]\u001B[0m Trial 5 finished with value: 0.7 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 3 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,169]\u001B[0m Trial 6 finished with value: 0.9666666666666667 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 6 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,171]\u001B[0m Trial 7 finished with value: 0.9 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,173]\u001B[0m Trial 8 finished with value: 0.7333333333333333 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:43:55,176]\u001B[0m Trial 9 finished with value: 0.8666666666666667 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 6 with value: 0.9666666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing KNN...\n",
      "Best params (KNN): {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Video Level Accuracy (KNN + PCA): 0.9667\n",
      "\n",
      "--- Running Experiment: uniform_stdscaler ---\n",
      "Extracting features...\n",
      "Processing 240 videos with -1 jobs...\n",
      "Processing 30 videos with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:22,145]\u001B[0m A new study created in memory with name: no-name-668bce2d-c755-4d88-8b91-a5083bea56b6\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction time: 26.82s\n",
      "Training Frame-Level Model...\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:23,660]\u001B[0m Trial 0 finished with value: 0.99375 and parameters: {'C': 0.11035255258703651, 'gamma': 0.03099734567774172, 'kernel': 'linear'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:25,949]\u001B[0m Trial 1 finished with value: 0.65625 and parameters: {'C': 1.270019263670051, 'gamma': 0.550146633344877, 'kernel': 'rbf'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:27,610]\u001B[0m Trial 2 finished with value: 0.9854166666666667 and parameters: {'C': 0.9407938750760856, 'gamma': 0.01501702396074752, 'kernel': 'linear'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:28,367]\u001B[0m Trial 3 finished with value: 0.9583333333333334 and parameters: {'C': 0.3723430817230827, 'gamma': 0.16052394228218742, 'kernel': 'poly'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:29,939]\u001B[0m Trial 4 finished with value: 0.9854166666666667 and parameters: {'C': 1.6577526271739336, 'gamma': 0.002479438445240722, 'kernel': 'linear'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:31,343]\u001B[0m Trial 5 finished with value: 0.9854166666666667 and parameters: {'C': 25.55686221770336, 'gamma': 0.04998070793266182, 'kernel': 'linear'}. Best is trial 0 with value: 0.99375.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:31,858]\u001B[0m Trial 6 finished with value: 0.9958333333333333 and parameters: {'C': 0.41735587062508644, 'gamma': 0.0030620730806854386, 'kernel': 'rbf'}. Best is trial 6 with value: 0.9958333333333333.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:32,613]\u001B[0m Trial 7 finished with value: 0.39791666666666664 and parameters: {'C': 0.08082293193562998, 'gamma': 0.0014723440937471073, 'kernel': 'poly'}. Best is trial 6 with value: 0.9958333333333333.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:33,310]\u001B[0m Trial 8 finished with value: 0.9583333333333334 and parameters: {'C': 72.70261773836934, 'gamma': 1.2173505145573373, 'kernel': 'poly'}. Best is trial 6 with value: 0.9958333333333333.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:33,953]\u001B[0m Trial 9 finished with value: 0.35 and parameters: {'C': 0.13443326855987933, 'gamma': 3.179671941491866, 'kernel': 'rbf'}. Best is trial 6 with value: 0.9958333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.41735587062508644, 'gamma': 0.0030620730806854386, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:34,644]\u001B[0m A new study created in memory with name: no-name-bdd1ad8c-f807-4021-8255-9891f650ca2e\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Level Accuracy (Voting): 1.0000\n",
      "Training Video-Level Aggregated Model...\n",
      "PCA reduced dim from 432 to 37\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:34,820]\u001B[0m Trial 0 finished with value: 0.9 and parameters: {'C': 0.47966050043947905, 'gamma': 0.02347808187799514, 'kernel': 'poly'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:34,985]\u001B[0m Trial 1 finished with value: 0.36666666666666664 and parameters: {'C': 0.720377167595496, 'gamma': 2.723643626525303, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:35,168]\u001B[0m Trial 2 finished with value: 1.0 and parameters: {'C': 4.156994223359954, 'gamma': 0.003604620044945133, 'kernel': 'linear'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:35,337]\u001B[0m Trial 3 finished with value: 0.9333333333333333 and parameters: {'C': 0.04619808587870525, 'gamma': 1.7547191573531762, 'kernel': 'linear'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:35,540]\u001B[0m Trial 4 finished with value: 0.9 and parameters: {'C': 8.69866238707858, 'gamma': 2.3701084193639392, 'kernel': 'poly'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:35,865]\u001B[0m Trial 5 finished with value: 0.36666666666666664 and parameters: {'C': 0.04025158043733444, 'gamma': 4.955267871801212, 'kernel': 'rbf'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:36,070]\u001B[0m Trial 6 finished with value: 1.0 and parameters: {'C': 23.16465918444033, 'gamma': 0.3917777653694065, 'kernel': 'linear'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:36,235]\u001B[0m Trial 7 finished with value: 0.8666666666666667 and parameters: {'C': 0.13526903575321805, 'gamma': 0.009022048886663473, 'kernel': 'poly'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:36,395]\u001B[0m Trial 8 finished with value: 0.9 and parameters: {'C': 6.054068085960249, 'gamma': 0.27746174190953593, 'kernel': 'poly'}. Best is trial 2 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:36,571]\u001B[0m Trial 9 finished with value: 0.9 and parameters: {'C': 26.940330055283045, 'gamma': 0.10732271049550253, 'kernel': 'poly'}. Best is trial 2 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 4.156994223359954, 'gamma': 0.003604620044945133, 'kernel': 'linear'}\n",
      "Video Level Accuracy (SVM + PCA): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:36,886]\u001B[0m A new study created in memory with name: no-name-5b774466-f5f1-41b6-9f01-78952b10d167\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:37,343]\u001B[0m Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 220, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:37,641]\u001B[0m Trial 1 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 240, 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:37,935]\u001B[0m Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 197, 'max_depth': 48, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:38,560]\u001B[0m Trial 3 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 231, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:39,160]\u001B[0m Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 163, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:39,292]\u001B[0m Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:39,938]\u001B[0m Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 204, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:40,257]\u001B[0m Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 218, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:40,828]\u001B[0m Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 198, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:41,550]\u001B[0m Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 298, 'max_depth': 47, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (RF): {'n_estimators': 220, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:42,135]\u001B[0m A new study created in memory with name: no-name-c7ea3b8a-3796-44b1-b34f-c217f44537c7\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,142]\u001B[0m Trial 0 finished with value: 0.9 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,149]\u001B[0m Trial 1 finished with value: 0.8 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Level Accuracy (RF): 1.0000\n",
      "Optimizing KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:44:42,154]\u001B[0m Trial 2 finished with value: 0.8666666666666667 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,157]\u001B[0m Trial 3 finished with value: 0.7666666666666667 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,159]\u001B[0m Trial 4 finished with value: 0.8333333333333334 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,192]\u001B[0m Trial 5 finished with value: 0.7666666666666667 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,221]\u001B[0m Trial 6 finished with value: 0.8 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,223]\u001B[0m Trial 7 finished with value: 0.8333333333333334 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,232]\u001B[0m Trial 8 finished with value: 0.8 and parameters: {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 0 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:44:42,236]\u001B[0m Trial 9 finished with value: 0.7666666666666667 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (KNN): {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Video Level Accuracy (KNN + PCA): 0.9000\n",
      "\n",
      "--- Running Experiment: dense_stdscaler ---\n",
      "Extracting features...\n",
      "Processing 240 videos with -1 jobs...\n",
      "Processing 30 videos with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:45:59,777]\u001B[0m A new study created in memory with name: no-name-ac1292ac-49a3-47d7-b6e0-c50aacde2738\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction time: 77.36s\n",
      "Training Frame-Level Model...\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:01,321]\u001B[0m Trial 0 finished with value: 0.9612948627726953 and parameters: {'C': 12.11206695934873, 'gamma': 0.0316436842047391, 'kernel': 'poly'}. Best is trial 0 with value: 0.9612948627726953.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:04,219]\u001B[0m Trial 1 finished with value: 0.9929627023223082 and parameters: {'C': 38.281765241332984, 'gamma': 0.0010256273253940558, 'kernel': 'linear'}. Best is trial 1 with value: 0.9929627023223082.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:06,489]\u001B[0m Trial 2 finished with value: 0.9992962702322308 and parameters: {'C': 0.07605609004555121, 'gamma': 0.7378643657469214, 'kernel': 'linear'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:08,631]\u001B[0m Trial 3 finished with value: 0.9225897255453905 and parameters: {'C': 1.416346363395067, 'gamma': 0.005494169282312147, 'kernel': 'poly'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:15,727]\u001B[0m Trial 4 finished with value: 0.6108374384236454 and parameters: {'C': 3.778132260144092, 'gamma': 1.827573346439722, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:17,452]\u001B[0m Trial 5 finished with value: 0.9612948627726953 and parameters: {'C': 0.2722533417130183, 'gamma': 0.1349920388200173, 'kernel': 'poly'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:20,396]\u001B[0m Trial 6 finished with value: 0.9929627023223082 and parameters: {'C': 1.9802164366551103, 'gamma': 0.017865493567554753, 'kernel': 'linear'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:24,646]\u001B[0m Trial 7 finished with value: 0.40464461646727656 and parameters: {'C': 0.03792805131205086, 'gamma': 2.3546970695333873, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:26,105]\u001B[0m Trial 8 finished with value: 0.9725545390570021 and parameters: {'C': 21.922851409214303, 'gamma': 0.011120196270674383, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:27,654]\u001B[0m Trial 9 finished with value: 0.995777621393385 and parameters: {'C': 0.021422506698247665, 'gamma': 9.214306819961765, 'kernel': 'linear'}. Best is trial 2 with value: 0.9992962702322308.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.07605609004555121, 'gamma': 0.7378643657469214, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:30,153]\u001B[0m A new study created in memory with name: no-name-0d626eaf-8755-4f81-ac5d-1b816ebec0ba\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Level Accuracy (Voting): 1.0000\n",
      "Training Video-Level Aggregated Model...\n",
      "PCA reduced dim from 432 to 34\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:30,338]\u001B[0m Trial 0 finished with value: 1.0 and parameters: {'C': 0.015251804610922239, 'gamma': 2.822311800001481, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:30,565]\u001B[0m Trial 1 finished with value: 0.9666666666666667 and parameters: {'C': 0.43263152676611355, 'gamma': 0.010467246837874847, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:30,731]\u001B[0m Trial 2 finished with value: 0.4666666666666667 and parameters: {'C': 0.05498753127030705, 'gamma': 0.17908670403869134, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:30,912]\u001B[0m Trial 3 finished with value: 0.9666666666666667 and parameters: {'C': 1.937462811803805, 'gamma': 2.156385707821332, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,107]\u001B[0m Trial 4 finished with value: 0.9666666666666667 and parameters: {'C': 0.567651227745078, 'gamma': 0.016006110406772123, 'kernel': 'linear'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,297]\u001B[0m Trial 5 finished with value: 0.8333333333333334 and parameters: {'C': 42.769864563133474, 'gamma': 0.005346361917027663, 'kernel': 'poly'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,494]\u001B[0m Trial 6 finished with value: 1.0 and parameters: {'C': 56.56034639433197, 'gamma': 0.004219611978536498, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,668]\u001B[0m Trial 7 finished with value: 0.8333333333333334 and parameters: {'C': 0.030417965562910876, 'gamma': 0.037497616316910745, 'kernel': 'poly'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,819]\u001B[0m Trial 8 finished with value: 0.4666666666666667 and parameters: {'C': 17.69734408236585, 'gamma': 2.344307219411088, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:31,952]\u001B[0m Trial 9 finished with value: 0.4666666666666667 and parameters: {'C': 0.01826146880192767, 'gamma': 0.41458576802679176, 'kernel': 'rbf'}. Best is trial 0 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.015251804610922239, 'gamma': 2.822311800001481, 'kernel': 'linear'}\n",
      "Video Level Accuracy (SVM + PCA): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:32,278]\u001B[0m A new study created in memory with name: no-name-94646ed6-5d64-42e6-8a11-41f041eb5fab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:32,653]\u001B[0m Trial 0 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 116, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:33,117]\u001B[0m Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 133, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:34,119]\u001B[0m Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 264, 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:34,834]\u001B[0m Trial 3 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 215, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:35,571]\u001B[0m Trial 4 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 203, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:36,158]\u001B[0m Trial 5 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 233, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:36,486]\u001B[0m Trial 6 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 144, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:36,886]\u001B[0m Trial 7 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 138, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,115]\u001B[0m Trial 8 finished with value: 0.9333333333333333 and parameters: {'n_estimators': 75, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 1 with value: 1.0.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,458]\u001B[0m Trial 9 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 77, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 1 with value: 1.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (RF): {'n_estimators': 133, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-08 20:46:37,800]\u001B[0m A new study created in memory with name: no-name-6e0994fb-efe9-494d-9e8c-97533a0d2714\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,803]\u001B[0m Trial 0 finished with value: 0.8333333333333334 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,806]\u001B[0m Trial 1 finished with value: 0.8 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,808]\u001B[0m Trial 2 finished with value: 0.8666666666666667 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 2 with value: 0.8666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,810]\u001B[0m Trial 3 finished with value: 0.8 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 2 with value: 0.8666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,813]\u001B[0m Trial 4 finished with value: 0.8333333333333334 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 2 with value: 0.8666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,815]\u001B[0m Trial 5 finished with value: 0.8666666666666667 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 2 with value: 0.8666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,816]\u001B[0m Trial 6 finished with value: 0.7333333333333333 and parameters: {'n_neighbors': 17, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 2 with value: 0.8666666666666667.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,822]\u001B[0m Trial 7 finished with value: 0.9 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 7 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,830]\u001B[0m Trial 8 finished with value: 0.8666666666666667 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 7 with value: 0.9.\u001B[0m\n",
      "\u001B[32m[I 2026-02-08 20:46:37,833]\u001B[0m Trial 9 finished with value: 0.8 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 7 with value: 0.9.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Level Accuracy (RF): 1.0000\n",
      "Optimizing KNN...\n",
      "Best params (KNN): {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Video Level Accuracy (KNN + PCA): 0.9000\n",
      "\n",
      "--- Summary ---\n",
      "Baseline (Voting): 1.0\n",
      "Baseline (SVM Agg): 1.0\n",
      "Baseline (RF Agg): 1.0\n",
      "Baseline (KNN Agg): 0.9666666666666667\n",
      "\n",
      "StdScaler (Voting): 1.0\n",
      "StdScaler (SVM Agg): 1.0\n",
      "StdScaler (RF Agg): 1.0\n",
      "StdScaler (KNN Agg): 0.9\n",
      "\n",
      "Dense (Voting): 1.0\n",
      "Dense (SVM Agg): 1.0\n",
      "Dense (RF Agg): 1.0\n",
      "Dense (KNN Agg): 0.9\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis\n",
    "\n",
    "## 1. Performance Comparison\n",
    "\n",
    "We evaluated three experimental configurations using different sampling strategies and normalization techniques. The models compared include Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN) using both Frame-Level Voting and Video-Level Aggregation strategies.\n",
    "\n",
    "### Accuracy Summary\n",
    "\n",
    "| Experiment | Frame Voting (SVM) | Video Agg (SVM) | Video Agg (RF) | Video Agg (KNN) |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| **Baseline** (Uniform, MinMax) | **1.0000** | **1.0000** | **1.0000** | 0.9667 |\n",
    "| **Improved 1** (Uniform, StdScaler) | **1.0000** | **1.0000** | **1.0000** | 0.9000 |\n",
    "| **Improved 2** (Dense, StdScaler) | **1.0000** | **1.0000** | **1.0000** | 0.9000 |\n",
    "\n",
    "**Observations:**\n",
    "- **Perfect Classification:** The SVM and Random Forest models achieved a perfect accuracy of **100%** across all experimental setups on the validation set. This suggests that the extracted features are highly discriminative for the three classes (Diving, Drumming, Juggling balls).\n",
    "- **KNN Performance:** KNN slightly lagged behind, achieving 90-96.7% accuracy. It performed best with MinMax scaling (96.7%) compared to StandardScaler (90%), indicating sensitivity to the scaling method.\n",
    "- **Robustness:** The high performance indicates that the classical feature engineering pipeline (combining Spatial and Temporal features) is robust for this specific dataset.\n",
    "\n",
    "### Visual Analysis\n",
    "\n",
    "#### Confusion Matrices\n",
    "The confusion matrices for the best performing models (SVM/RF) show clear diagonal dominance with zero misclassifications.\n",
    "![Confusion Matrix Baseline SVM](results_classical/cm_baseline_uniform_minmax_svm.png)\n",
    "\n",
    "#### ROC Curves\n",
    "The ROC curves confirm the perfect separation with Area Under Curve (AUC) of 1.00 for all classes in SVM and RF models.\n",
    "![ROC Baseline SVM](results_classical/roc_baseline_uniform_minmax_svm.png)\n",
    "\n",
    "## 2. Computational Analysis\n",
    "\n",
    "### Training & Extraction Time\n",
    "Feature extraction is the most computationally expensive part of the classical pipeline.\n",
    "\n",
    "| Experiment | Extraction Time (s) | Relative Cost |\n",
    "| :--- | :---: | :---: |\n",
    "| **Baseline** (Uniform, 16 frames) | 29.14s | 1.0x |\n",
    "| **StdScaler** (Uniform, 16 frames) | 26.82s | ~0.9x |\n",
    "| **Dense** (Stride 5) | **77.36s** | **2.9x** |\n",
    "\n",
    "**Key Findings:**\n",
    "- **Dense Sampling Cost:** Dense sampling (processing every 5th frame) took nearly **3x longer** than uniform sampling (16 frames). Since accuracy did not improve (already at 100%), the extra computational cost of dense sampling is unjustified for this dataset.\n",
    "- **Normalization Impact:** The choice of scaler (MinMax vs Standard) had negligible impact on extraction time.\n",
    "\n",
    "### Model Complexity (Best Parameters)\n",
    "- **SVM:**\n",
    "    - Baseline: `C=6.97`, `RBF` kernel.\n",
    "    - Dense: `C=0.015`, `Linear` kernel.\n",
    "    - *Insight:* Dense sampling allowed a simpler Linear kernel to work effectively, likely because more data points smoothed out the feature space.\n",
    "- **Random Forest:**\n",
    "    - Baseline: `95 estimators`, `depth 28`.\n",
    "    - Dense: `133 estimators`, `depth 7`.\n",
    "    - *Insight:* Dense sampling resulted in shallower trees (depth 7 vs 28), suggesting that with more frames, the features became more robust, requiring less complex decision boundaries.\n",
    "- **Dimensionality Reduction (PCA):**\n",
    "    - Original Feature Count: 432\n",
    "    - Reduced Feature Count (95% Variance): ~35\n",
    "    - *Insight:* **92% of the feature space was redundant.** PCA successfully compressed the information, speeding up the classifier training without loss of accuracy.\n",
    "\n",
    "## 3. Feature Analysis\n",
    "\n",
    "### Extracted Features\n",
    "The pipeline extracted a rich set of 432 features per video (before PCA), comprising:\n",
    "- **Spatial:** Color Histograms, GLCM (Texture), LBP (Pattern), Gabor (Texture), Canny (Edge), HOG (Shape).\n",
    "- **Temporal:** Optical Flow Statistics, Motion Trajectory.\n",
    "\n",
    "### Representation Learning (PCA)\n",
    "The drastic reduction from 432 to ~35 components while maintaining 100% accuracy implies that the classes are linearly separable in the lower-dimensional manifold.\n",
    "- **Diving:** Likely characterized by specific motion patterns (vertical flow) and background colors (pool blue).\n",
    "- **Drumming:** Characterized by repetitive localized motion and specific object textures.\n",
    "- **Juggling:** Complex erratic motion patterns.\n",
    "\n",
    "## 4. Trade-off Analysis\n",
    "\n",
    "### Accuracy vs. Computational Cost\n",
    "- **Winner:** **Baseline (Uniform Sampling + MinMax)**.\n",
    "- **Reasoning:** It achieves the same perfect accuracy (100%) as the expensive Dense strategy but is **3x faster**. The computational overhead of dense sampling yields no return on investment for this specific classification task.\n",
    "\n",
    "### Data Efficiency\n",
    "- The models performed perfectly even with sparse uniform sampling (16 frames per video). This suggests high data efficiencythe key discriminative features are global and temporal, not requiring a dense frame-by-frame analysis.\n",
    "\n",
    "### Interpretability vs. Performance\n",
    "- **Random Forest** offers the best balance. It achieved 100% accuracy and provides feature importance (interpretable), whereas SVM (especially with RBF kernel) is a black box.\n",
    "- The **Video-Level Aggregation** approach (using statistical potential of features) is more interpretable and faster to train than Frame-Level Voting, as it reduces the number of training samples for the final classifier significantly.\n",
    "\n",
    "## Conclusion\n",
    "For the task of classifying Diving, Drumming, and Juggling balls:\n",
    "1.  **Classical methods are sufficient:** Deep learning may be overkill given that classical feature extraction + SVM/RF achieves 100% accuracy.\n",
    "2.  **Uniform Sampling is optimal:** Dense sampling triples the cost without performance gain.\n",
    "3.  **Recommendations:** Use the **Random Forest** classifier with **Uniform Sampling**. It is fast, accurate (100%), and offers interpretability.\n"
   ],
   "id": "eed4f42a7fff8b9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
