{
 "cells": [
  {
   "cell_type": "code",
   "id": "644d2648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:25.964230448Z",
     "start_time": "2026-02-08T13:18:25.891518372Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "44d5e7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:26.041940706Z",
     "start_time": "2026-02-08T13:18:25.968148047Z"
    }
   },
   "source": [
    "# Set device\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "1c615763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:26.092518535Z",
     "start_time": "2026-02-08T13:18:26.044084806Z"
    }
   },
   "source": [
    "# Define transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "95341bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:26.144645078Z",
     "start_time": "2026-02-08T13:18:26.094123936Z"
    }
   },
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df, num_frames=16, transform=None):\n",
    "        self.df = df\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.df.iloc[idx]['clip_path']\n",
    "        label = self.df.iloc[idx]['encoded_label']\n",
    "\n",
    "        # Construct absolute path if needed, assuming relative to CWD\n",
    "        if not os.path.exists(video_path):\n",
    "             # Try to fix path if it starts with ./\n",
    "             if video_path.startswith(\"./\"):\n",
    "                 video_path = video_path[2:]\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if total_frames <= 0:\n",
    "             print(f\"Warning: Video {video_path} has 0 frames or cannot be read.\")\n",
    "             return torch.zeros(self.num_frames, 3, 224, 224), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        indices = torch.linspace(0, total_frames - 1, self.num_frames).long()\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            if i in indices:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                else:\n",
    "                    frame = torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                frames.append(frame)\n",
    "        cap.release()\n",
    "        \n",
    "        # padding if not enough frames\n",
    "        while len(frames) < self.num_frames:\n",
    "             if len(frames) > 0:\n",
    "                frames.append(frames[-1])\n",
    "             else:\n",
    "                # Should not happen if total_frames > 0\n",
    "                return torch.zeros(self.num_frames, 3, 224, 224), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return torch.stack(frames), torch.tensor(label, dtype=torch.long)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "689a8c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:26.193635456Z",
     "start_time": "2026-02-08T13:18:26.145587799Z"
    }
   },
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for videos, labels in loader:\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(videos)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Val/Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "4929567c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:18:26.242532722Z",
     "start_time": "2026-02-08T13:18:26.194503752Z"
    }
   },
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer for parameters that require grad\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (videos, labels) in enumerate(train_loader):\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"Validating...\")\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        \n",
    "        # Step scheduler\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"Saved best model with acc: {best_acc:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "53af3757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T13:19:34.519210173Z",
     "start_time": "2026-02-08T13:18:26.243320268Z"
    }
   },
   "source": [
    "# Load DataFrames\n",
    "print(\"Loading DataFrames...\")\n",
    "train_df = pd.read_csv(\"./dataset/splits/train.csv\", index_col='index')\n",
    "val_df = pd.read_csv(\"./dataset/splits/validation.csv\", index_col='index')\n",
    "test_df = pd.read_csv(\"./dataset/splits/test.csv\", index_col='index')\n",
    "    \n",
    "# Create Datasets\n",
    "print(\"Creating Datasets...\")\n",
    "dataset = VideoDataset(train_df, 16, transform=train_transforms)\n",
    "val_dataset = VideoDataset(val_df, 16, transform=test_transforms)\n",
    "test_dataset = VideoDataset(test_df, 16, transform=test_transforms)\n",
    "\n",
    "# Create Loaders\n",
    "# Increased batch size to 4. Adjust as needed based on VRAM.\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize Model\n",
    "print(\"Initializing Model...\")\n",
    "model = VideoClassifier(num_classes=3).to(DEVICE)\n",
    "\n",
    "# Train\n",
    "print(\"Starting Training...\")\n",
    "train_model(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "# Check best model on test set\n",
    "print(\"Loading best model for testing...\")\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Evaluating on Test Set...\")\n",
    "evaluate_model(model, test_loader)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataFrames...\n",
      "Creating Datasets...\n",
      "Initializing Model...\n",
      "Starting Training...\n",
      "Batch 0, Loss: 1.1065\n",
      "Batch 10, Loss: 0.1080\n",
      "Batch 20, Loss: 0.1245\n",
      "Batch 30, Loss: 0.1030\n",
      "Batch 40, Loss: 0.2507\n",
      "Batch 50, Loss: 0.0453\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 1/10, Loss: 0.4526, Val Acc: 1.0000\n",
      "Saved best model with acc: 1.0000\n",
      "Batch 0, Loss: 0.1088\n",
      "Batch 10, Loss: 0.0149\n",
      "Batch 20, Loss: 0.0212\n",
      "Batch 30, Loss: 0.0203\n",
      "Batch 40, Loss: 0.0694\n",
      "Batch 50, Loss: 0.0089\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 2/10, Loss: 0.1298, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0718\n",
      "Batch 10, Loss: 0.0112\n",
      "Batch 20, Loss: 0.0066\n",
      "Batch 30, Loss: 0.0935\n",
      "Batch 40, Loss: 0.0790\n",
      "Batch 50, Loss: 0.0060\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 3/10, Loss: 0.1678, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0360\n",
      "Batch 10, Loss: 0.0617\n",
      "Batch 20, Loss: 0.0239\n",
      "Batch 30, Loss: 0.0655\n",
      "Batch 40, Loss: 0.0708\n",
      "Batch 50, Loss: 0.0034\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 4/10, Loss: 0.1350, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0699\n",
      "Batch 10, Loss: 0.0692\n",
      "Batch 20, Loss: 0.0050\n",
      "Batch 30, Loss: 1.8472\n",
      "Batch 40, Loss: 0.0359\n",
      "Batch 50, Loss: 0.0026\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 5/10, Loss: 0.0895, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0041\n",
      "Batch 10, Loss: 0.0019\n",
      "Batch 20, Loss: 0.0021\n",
      "Batch 30, Loss: 0.0421\n",
      "Batch 40, Loss: 0.0140\n",
      "Batch 50, Loss: 0.0218\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 6/10, Loss: 0.0950, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0033\n",
      "Batch 10, Loss: 0.0021\n",
      "Batch 20, Loss: 0.0034\n",
      "Batch 30, Loss: 0.0050\n",
      "Batch 40, Loss: 0.0037\n",
      "Batch 50, Loss: 0.0051\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 7/10, Loss: 0.1578, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0024\n",
      "Batch 10, Loss: 0.0014\n",
      "Batch 20, Loss: 0.0362\n",
      "Batch 30, Loss: 0.0502\n",
      "Batch 40, Loss: 0.0042\n",
      "Batch 50, Loss: 0.0031\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 8/10, Loss: 0.0461, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0017\n",
      "Batch 10, Loss: 0.0297\n",
      "Batch 20, Loss: 0.0072\n",
      "Batch 30, Loss: 0.0341\n",
      "Batch 40, Loss: 0.0024\n",
      "Batch 50, Loss: 0.0148\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 9/10, Loss: 0.0240, Val Acc: 1.0000\n",
      "Batch 0, Loss: 0.0023\n",
      "Batch 10, Loss: 0.0209\n",
      "Batch 20, Loss: 0.0111\n",
      "Batch 30, Loss: 0.0385\n",
      "Batch 40, Loss: 0.0066\n",
      "Batch 50, Loss: 0.0865\n",
      "Validating...\n",
      "Val/Test Accuracy: 1.0000\n",
      "Epoch 10/10, Loss: 0.0585, Val Acc: 1.0000\n",
      "Loading best model for testing...\n",
      "Evaluating on Test Set...\n",
      "Val/Test Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
