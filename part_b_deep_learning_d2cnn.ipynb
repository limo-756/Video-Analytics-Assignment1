{
 "cells": [
  {
   "cell_type": "code",
   "id": "644d2648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.174402659Z",
     "start_time": "2026-02-08T16:47:14.121933767Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "44d5e7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.235561927Z",
     "start_time": "2026-02-08T16:47:14.175038426Z"
    }
   },
   "source": [
    "# Set device\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "1c615763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.294276043Z",
     "start_time": "2026-02-08T16:47:14.238748451Z"
    }
   },
   "source": [
    "# Define transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "95341bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.344103089Z",
     "start_time": "2026-02-08T16:47:14.295040980Z"
    }
   },
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df, num_frames=16, transform=None):\n",
    "        self.df = df\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.df.iloc[idx]['clip_path']\n",
    "        label = self.df.iloc[idx]['encoded_label']\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "             if video_path.startswith(\"./\"):\n",
    "                 video_path = video_path[2:]\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if total_frames <= 0:\n",
    "             return torch.zeros(self.num_frames, 3, 224, 224), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        indices = torch.linspace(0, total_frames - 1, self.num_frames).long()\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            if i in indices:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                else:\n",
    "                    frame = torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0\n",
    "                frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        while len(frames) < self.num_frames:\n",
    "             if len(frames) > 0:\n",
    "                frames.append(frames[-1])\n",
    "             else:\n",
    "                return torch.zeros(self.num_frames, 3, 224, 224), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return torch.stack(frames), torch.tensor(label, dtype=torch.long)\n"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.404021380Z",
     "start_time": "2026-02-08T16:47:14.344753462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VideoClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, pooling='avg', dropped_rate=0.5):\n",
    "        super(VideoClassifier, self).__init__()\n",
    "        resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        # Freeze/Unfreeze logic as per train_improved\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone[6:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.pooling = pooling\n",
    "        self.dropout = nn.Dropout(dropped_rate)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        # x shape: (Batch, Frames, C, H, W)\n",
    "        batch_size, T, C, H, W = x.shape\n",
    "        x = x.view(batch_size * T, C, H, W)\n",
    "\n",
    "        features = self.backbone(x)\n",
    "        features = features.view(batch_size, T, 512)\n",
    "\n",
    "        if self.pooling == 'avg':\n",
    "            combined = torch.mean(features, dim=1)\n",
    "        else:\n",
    "            combined, _ = torch.max(features, dim=1)\n",
    "\n",
    "        if return_features:\n",
    "            return combined\n",
    "\n",
    "        combined = self.dropout(combined)\n",
    "        return self.fc(combined)\n"
   ],
   "id": "d0c9dbf740b334e1",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.461937900Z",
     "start_time": "2026-02-08T16:47:14.406208860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for videos, labels in train_loader:\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        val_acc, _, _, _ = evaluate_model(model, val_loader)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    return total_time\n"
   ],
   "id": "18b4813b6eb2f5a0",
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "689a8c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.510074791Z",
     "start_time": "2026-02-08T16:47:14.462414806Z"
    }
   },
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, labels in loader:\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(videos)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:47:14.557465967Z",
     "start_time": "2026-02-08T16:47:14.510977552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n"
   ],
   "id": "b2e085acfc547249",
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "53af3757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T16:48:18.166346374Z",
     "start_time": "2026-02-08T16:47:14.558738828Z"
    }
   },
   "source": [
    "def main():\n",
    "    # 1. Setup Data\n",
    "    train_df = pd.read_csv(\"./dataset/splits/train.csv\", index_col='index')\n",
    "    val_df = pd.read_csv(\"./dataset/splits/validation.csv\", index_col='index')\n",
    "    test_df = pd.read_csv(\"./dataset/splits/test.csv\", index_col='index')\n",
    "\n",
    "    # Verify classes\n",
    "    # Assuming standard mapping: 'Diving': 0, 'Drumming': 1, 'JugglingBalls': 2\n",
    "    # But usually encoded_label is present.\n",
    "    classes = ['Diving', 'Drumming', 'JugglingBalls'] # Based on prompt description\n",
    "\n",
    "    dataset = VideoDataset(train_df, 16, transform=train_transforms)\n",
    "    val_dataset = VideoDataset(val_df, 16, transform=test_transforms)\n",
    "    test_dataset = VideoDataset(test_df, 16, transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 2. Model & Computational Analysis (Memory & Params)\n",
    "    print(\"--- Computational Analysis ---\")\n",
    "    model = VideoClassifier(num_classes=3).to(DEVICE)\n",
    "    params = count_parameters(model)\n",
    "    print(f\"Model Parameters: {params}\")\n",
    "\n",
    "    # Measure memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # 3. Training & Timing\n",
    "    print(\"\\n--- Training ---\")\n",
    "    training_time = train_model(model, train_loader, val_loader, epochs=10)\n",
    "    print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        max_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "        print(f\"Peak VRAM during training: {max_mem:.2f} MB\")\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "    # 4. Inference Time Analysis\n",
    "    print(\"\\n--- Inference Speed Test ---\")\n",
    "    model.eval()\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for videos, _ in test_loader:\n",
    "            videos = videos.to(DEVICE)\n",
    "            start = time.time()\n",
    "            _ = model(videos)\n",
    "            end = time.time()\n",
    "            # Batch size is 4, so time per video is (end-start)/4\n",
    "            times.append((end-start) / videos.size(0))\n",
    "\n",
    "    avg_inference_time = np.mean(times)\n",
    "    print(f\"Average Inference Time per Video: {avg_inference_time:.4f} seconds\")\n",
    "    print(f\"FPS: {1.0/avg_inference_time:.2f}\")\n",
    "\n",
    "    # 5. Performance Analysis\n",
    "    print(\"\\n--- Performance Analysis ---\")\n",
    "    acc, y_true, y_pred, y_prob = evaluate_model(model, test_loader)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    # Save CM Plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.savefig('results_deep_learning_2dcnn/confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # ROC / AUC\n",
    "    # Binarize labels for ROC\n",
    "    y_true_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "    n_classes = y_true_bin.shape[1]\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {classes[i]} (area = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('results_deep_learning_2dcnn/roc_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Feature Analysis (t-SNE)\n",
    "    print(\"\\n--- Feature Analysis (t-SNE) ---\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, labels in test_loader:\n",
    "            videos = videos.to(DEVICE)\n",
    "            feats = model(videos, return_features=True)\n",
    "            features_list.append(feats.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=min(5, features.shape[0]-1), random_state=42)\n",
    "    features_embedded = tsne.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i, c in enumerate(classes):\n",
    "        idx = labels == i\n",
    "        plt.scatter(features_embedded[idx, 0], features_embedded[idx, 1], label=c, alpha=0.6)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE of Learned Features')\n",
    "    plt.savefig('results_deep_learning_2dcnn/tsne.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"All results saved to results_deep_learning_2dcnn/\")\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computational Analysis ---\n",
      "Model Parameters: 11178051\n",
      "\n",
      "--- Training ---\n",
      "Epoch 1/10, Loss: 0.4179, Val Acc: 1.0000\n",
      "Epoch 2/10, Loss: 0.2599, Val Acc: 1.0000\n",
      "Epoch 3/10, Loss: 0.1101, Val Acc: 1.0000\n",
      "Epoch 4/10, Loss: 0.1093, Val Acc: 1.0000\n",
      "Epoch 5/10, Loss: 0.1425, Val Acc: 1.0000\n",
      "Epoch 6/10, Loss: 0.0681, Val Acc: 1.0000\n",
      "Epoch 7/10, Loss: 0.0666, Val Acc: 1.0000\n",
      "Epoch 8/10, Loss: 0.0482, Val Acc: 1.0000\n",
      "Epoch 9/10, Loss: 0.1045, Val Acc: 1.0000\n",
      "Epoch 10/10, Loss: 0.0853, Val Acc: 1.0000\n",
      "Total Training Time: 60.68 seconds\n",
      "Peak VRAM during training: 961.15 MB\n",
      "\n",
      "--- Inference Speed Test ---\n",
      "Average Inference Time per Video: 0.0005 seconds\n",
      "FPS: 1870.71\n",
      "\n",
      "--- Performance Analysis ---\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0 10]]\n",
      "\n",
      "--- Feature Analysis (t-SNE) ---\n",
      "All results saved to results_deep_learning_2dcnn/\n"
     ]
    }
   ],
   "execution_count": 90
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
